{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text-Preprocess.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaE-6ZuU0CpI",
        "colab_type": "code",
        "outputId": "2821b309-db00-4395-a80e-532d5b3a760e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "!pip install langdetect\n",
        "!pip install tweet-preprocessor\n",
        "!pip install nltk"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect) (1.12.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.7\n",
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/f8/810ec35c31cca89bc4f1a02c14b042b9ec6c19dd21f7ef1876874ef069a6/tweet-preprocessor-0.5.0.tar.gz\n",
            "Building wheels for collected packages: tweet-preprocessor\n",
            "  Building wheel for tweet-preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/27/cc/49938e98a2470802ebdefae9d2b3f524768e970c1ebbe2dc4a\n",
            "Successfully built tweet-preprocessor\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.5.0\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gSl6-DFDCMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "         u\"\\U00002702-\\U000027B0\"\n",
        "         u\"\\U000024C2-\\U0001F251\"\n",
        "         \"]+\", flags=re.UNICODE)\n",
        "\n",
        "emoticons_happy = set([\n",
        "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
        "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
        "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
        "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
        "    '<3'\n",
        "    ])\n",
        "\n",
        "emoticons_sad = set([\n",
        "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
        "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
        "    ':c', ':{', '>:\\\\', ';('\n",
        "    ])\n",
        "emoticons = emoticons_happy.union(emoticons_sad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI0xfLio0V6h",
        "colab_type": "code",
        "outputId": "b2852e42-7108-4524-bfbf-04ce57ad539d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "import langdetect\n",
        "import preprocessor as pre\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "\n",
        "words = set(nltk.corpus.words.words())\n",
        "\n",
        "#load data\n",
        "data = pd.read_csv(\"drive/My Drive/extracted/29.csv\")\n",
        "df = data.loc[:,:]\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "for index,row in df.iterrows():\n",
        "  df['text'][index] = re.sub(r'http\\S+', '', df['text'][index])\n",
        "\n",
        "\n",
        "#remove nan rows\n",
        "df = df[pd.notnull(df['text'])]\n",
        "\n",
        "def clean_tweets(tweet):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(tweet)\n",
        "    \n",
        "    tweet = re.sub(r':', '', tweet)\n",
        "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
        "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
        "    tweet = emoji_pattern.sub(r'', tweet)\n",
        "    \n",
        "    filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
        "    filtered_tweet = []\n",
        "    for w in word_tokens:\n",
        "        if w not in stop_words and w not in emoticons and w not in string.punctuation:\n",
        "            filtered_tweet.append(w)\n",
        "    return ' '.join(filtered_tweet)\n",
        "\n",
        "df = df[pd.notnull(df['text'])]\n",
        "\n",
        "for index,row in df.iterrows():\n",
        "  list2 = []\n",
        "  list3 = []\n",
        "  row['text'] = re.sub(r'@\\S+','', row['text'])\n",
        "  row['text'] = re.sub(r'RT','', row['text'])\n",
        "  #print(row['text'])\n",
        "  #print(list3)\n",
        "  #text = \" \".join(w for w in nltk.wordpunct_tokenize(row['text']) \\\n",
        "         #if w.lower() in words or not w.isalpha())\n",
        "  #text = pre.clean(str(text))\n",
        "  #print(text)\n",
        "  clean_text = clean_tweets(row['text'])\n",
        "  #print(clean_text)\n",
        "  list1 = list()\n",
        "  p = re.compile(\"[A-Z]|[a-z]\")\n",
        "  for x in clean_text:\n",
        "    if(x == ' '):\n",
        "      st = ''.join(list1)\n",
        "      list2.append(st)\n",
        "      list1 = []\n",
        "    if(p.match(x)):\n",
        "      list1.append(x)\n",
        "  st = ''.join(list1)\n",
        "  list2.append(st)\n",
        "  list2 = list(filter(None,list2)) \n",
        "  st1 = ' '.join(list2)\n",
        "  df['text'][index] = st1\n",
        "  \n",
        "  \n",
        "for index,row in df.iterrows():\n",
        "  if(df.loc[index]['text'] == ''):\n",
        "    df.drop([index], inplace = True)\n",
        "print(df['text'])\n",
        "\n",
        "df.to_csv(\"29.csv\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "Index(['entities.hashtags.0.text', 'entities.hashtags.1.text',\n",
            "       'entities.hashtags.2.text', 'entities.hashtags.3.text',\n",
            "       'entities.hashtags.4.text', 'entities.hashtags.5.text',\n",
            "       'favorite_count', 'reply_count', 'retweet_count', 'text',\n",
            "       'timestamp_ms'],\n",
            "      dtype='object')\n",
            "0                yeah keeping sharkboy lava girl mistake\n",
            "1      Incredible event last night put University Geo...\n",
            "2                          hums theme song Mash Too soon\n",
            "3                                         miss chaeyoung\n",
            "4      Where MeToo movement Illegal Alien From El Sal...\n",
            "5      Why I even make study plans past am I clearly ...\n",
            "6                                          bed rn really\n",
            "7      You right POS like civil Conservatives want de...\n",
            "8         take decision fast life limited decide want go\n",
            "9      amreading The Queen No Tomorrows Matt Maxwell ...\n",
            "10           OH WOW YOU ONE OF THEM ANTI BROOKLYN PEOPLE\n",
            "12      Buying new meat day one My whip I spoil way much\n",
            "13                                                I sure\n",
            "14     An important reminder young people around Worl...\n",
            "15                                      Remembers always\n",
            "16     New YouTube video The Skull Trooper Is Back HO...\n",
            "17     I trying figure I feel fucking shitty It money...\n",
            "18              use wear converse go way ur knees forget\n",
            "19                Probably rebels killed US Soldiers pas\n",
            "20                                             Only FIFA\n",
            "21     Happy PA week Dr James Bekeny made PAs cake sc...\n",
            "22     When shot Michael Myers times watched burn mov...\n",
            "23              Better Health Impressive Benefits Onions\n",
            "24     Hillary Clinton recently said one paid speeche...\n",
            "25     Bouquet best gift ideas bouquet flowers flower...\n",
            "26     BTP hired TOC s make visable presence services...\n",
            "27                               I love working downtown\n",
            "28     Jammin DJ Prince ft Skales Skaku Shaku AfroBea...\n",
            "29     Parents get deported lose children adoption Ho...\n",
            "30                     Thanks There error previous tweet\n",
            "                             ...                        \n",
            "810                       Never seen better man coverage\n",
            "811    Belen Giaquinta gives lunchtalk accountable co...\n",
            "812    Once pull emotions back remove current politic...\n",
            "813    ERIC HOLDER CALLS FOR VIOLENCE When Republican...\n",
            "814                                            beautiful\n",
            "815    When I someone I INTO THEM like I drop everyon...\n",
            "816    Hey Ted nt try managing Portland Oregon nt not...\n",
            "817    This awesome They also add graph toggle button...\n",
            "818                     Home since everyone left college\n",
            "819    Want work Memphis TN View latest opening Educa...\n",
            "820                                       Dude got boobs\n",
            "821    Had put career hold say new artistes go start ...\n",
            "822                         JOE MANCHIN WV one DEMOCRATS\n",
            "823                                        This go viral\n",
            "824    Interesting knowledge graph card kc musicrecor...\n",
            "825                      Time Ain Waiting On A Mf At All\n",
            "826                                  everybody temporary\n",
            "827            I soo pissed I missed wic appointment WTF\n",
            "828                                         Loveya JIMIN\n",
            "829    felt felt felt world FELT camila cabello power...\n",
            "830    Catch us week Thursday Friday Petticoat Lane S...\n",
            "831                                            Kiki love\n",
            "832    The truth centrist Democratic Party dead The n...\n",
            "833                           I try days awesome recipes\n",
            "834                             NeYo Because Of You Main\n",
            "835          Somebody still nt heard Please keep sharing\n",
            "836    Boomerang I invisible see Rick Flagg Where Har...\n",
            "837    Hello DEPASCAL Did I save nation past life Rea...\n",
            "838                                      s wip wednesday\n",
            "840    When organizing Trunk Treat candy find bag emp...\n",
            "Name: text, Length: 834, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnxiuRJa5hmZ",
        "colab_type": "code",
        "outputId": "eb6ab134-835b-41ac-f753-cd51bf967112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrJ3VBLxB3FK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gylA6mBPGuPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}